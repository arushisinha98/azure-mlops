## Notes from Udemy / learn.gov.sg: MLOps Fundamentals: CI/CD/CT Pipelines of ML with Azure Demo

MLOps = Machine Learning + Operations
- set of principles and practices to standardize and streamline the machine learning lifecycle management
- integration b/w development and operational processes
- teams collaborate to build, automate, test, and monitor the machine learning pipelines
- based on DevOps principles of continuous integration (CI), continuous delivery (CD), continuous training (CT)

ML >> Dev >> Ops
(data, design, model) >> (plan, create, package, verify) >> (configure, release, triggers, monitor)

traditional approach to an ML project:
- business understanding / requirement gathering
- data acquisition: identify data sources / formats, make source connections, create data lake
- data wrangling / transformations / pre-processing, exploratory data analysis, data visualization
- model selection / building / training / testing / validation
- model deployment (e.g. webservices, API)
    - model as a service = model is deployed into a framework to provide REST API endpoint
    - embedded deployment = model is packed into an application / software
- monitoring
- model retraining (on the new data)

subject matter experts
- provide business questions, goals, KPIs to achieve
- continuously evaluate the model performance
data scientists
- algorithm selection
- build, train, validate model
- hyperparameter tuning
data engineers
- data acquisition, data lake creation
- data wrangling, cleaning, tranformstion
- ETL pipelines
ML engineers
- operationalize model
- deployment

R&D phase -- mostly carried out by data scientists
data acquisition >> data preprocessing >> model building >> model training >> model validation
Operations phase -- mostly carried out by operational team
package >> compile >> deploy >> release >> monitor

data scientists are often engaged in other activities
- experiments predominantly carried out in isolation
- code is often not robust or scalable
operational team often has many questions when they received the POC created by data scientists
- what are the required dependencies?
- what feature parameters is the model trained on?
- what variable represents model output values?
- what is the data format to feed to the model?
- is model production ready?

productionization of a model is not smooth
- build and train model locally
- package
    - compile code
    - resolve dependencies
    - run scripts
- performance
    - scale out to train larger data sets
    - evaluate performance on larger data sets
    - load balancing
    - add parallelism
    - data partitioning
    - take GPU support
    - model preduction speed
- instrumentation
    - versioning, repo management, security, monitoring
    - versioning of algorithm + data + feature parameters + environment
    - reproducibility
- automation
    - continuous training
    
technical debt in ML:
configuration, data collection, feature extraction, versioning, resource management, process management tools, monitoring, serving infrastructure, analysis tools, ML code (smallest component)
