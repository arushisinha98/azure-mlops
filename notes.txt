## Notes from Udemy / learn.gov.sg: MLOps Fundamentals: CI/CD/CT Pipelines of ML with Azure Demo

MLOps = Machine Learning + Operations
- set of principles and practices to standardize and streamline the machine learning lifecycle management
- integration b/w development and operational processes
- teams collaborate to build, automate, test, and monitor the machine learning pipelines
- based on DevOps principles of continuous integration (CI), continuous delivery (CD), continuous training (CT)

ML >> Dev >> Ops
(data, design, model) >> (plan, create, package, verify) >> (configure, release, triggers, monitor)

traditional approach to an ML project:
- business understanding / requirement gathering
- data acquisition: identify data sources / formats, make source connections, create data lake
- data wrangling / transformations / pre-processing, exploratory data analysis, data visualization
- model selection / building / training / testing / validation
- model deployment (e.g. webservices, API)
    - model as a service = model is deployed into a framework to provide REST API endpoint
    - embedded deployment = model is packed into an application / software
- monitoring
- model retraining (on the new data)

subject matter experts
- provide business questions, goals, KPIs to achieve
- continuously evaluate the model performance
data scientists
- algorithm selection
- build, train, validate model
- hyperparameter tuning
data engineers
- data acquisition, data lake creation
- data wrangling, cleaning, tranformstion
- ETL pipelines
ML engineers
- operationalize model
- deployment

R&D phase -- mostly carried out by data scientists
data acquisition >> data preprocessing >> model building >> model training >> model validation
Operations phase -- mostly carried out by operational team
package >> compile >> deploy >> release >> monitor

data scientists are often engaged in other activities
- experiments predominantly carried out in isolation
- code is often not robust or scalable
operational team often has many questions when they received the POC created by data scientists
- what are the required dependencies?
- what feature parameters is the model trained on?
- what variable represents model output values?
- what is the data format to feed to the model?
- is model production ready?

productionization of a model is not smooth
- build and train model locally
- package
    - compile code
    - resolve dependencies
    - run scripts
- performance
    - scale out to train larger data sets
    - evaluate performance on larger data sets
    - load balancing
    - add parallelism
    - data partitioning
    - take GPU support
    - model preduction speed
- instrumentation
    - versioning, repo management, security, monitoring
    - versioning of algorithm + data + feature parameters + environment
    - reproducibility
- automation
    - continuous training
    
technical debt in ML:
configuration, data collection, feature extraction, versioning, resource management, process management tools, monitoring, serving infrastructure, analysis tools, ML code (smallest component)

MLOps = a culture with a set of principles, guidelines defined in a ML world to seamlessly integrate/automate the development phase with the operational phase

transition fiction
- use notebook templates that define common functionality (e.g. database connection template, fetching data, etc)
- proper documentation
version control system
- version control system for code, data, environment, and artifacts
performance
- leverage distributed computing and containerization tools (e.g. Docker, Kubernetes)
automation
- build workflows, CI/CD pipelines
- MLOps is pipeline centric: put pipelines in production rather than putting a model
monitoring
- powerful innovative monitoring tools to monitor data, features, distribution, latency, uptime, memory utilization, etc
- monitoring tools e.g. Prometheus, Grafana
continuous retraining
- automated retraining of models based on triggers or regular frequency

CI, build, test pipeline:
INPUTS:
- test
    - line and unit tests for code coverage, code quality
    - publish test results
- build
    - include dependencies (libraries + versions)
    - build images
- publish
    - publish the pipeline
OUTPUTS:
- packages
- executables
- images

MLOps creates a shared language among the extended team and invites automation
- data scientists can then focus on more research and experimentation while having the overall visibility of the deployed models
- ML engineers get less resistance from understanding the experiment; reproducibility is no longer a problem
- application developers do not need to change the code everytime the model changes; model and application are decoupled from each other
- risk & compliance team can streamline internal processes since complete lineage is maintained for easy audits
- clients can make better business decisions when they have the updated model giving predictions

DevOps VS MLOps
- more diverse teams
- iterative development cycle
- versioning of code, data, features, environments
- projects are compute intensive
- CI comprises testing and validation of code and data
- CD comprises deploying multiple pipelines
- monitor throughput latency, CPU utilizations, model accuracy, data drift, features along with basic health checks
- CI, CD, CT

Maturity Levels in MLOps
- Level 0
    - people: data scientists are siloed
    - data gathering: data scattered everywhere and gathered manually
    - development: manual activities that are passed on to operationalize
    - model release: manual and done by data scientists
    - no CI/CD
    - app integration and testing: heavily reliant on data scientist experise to implement
    - monitoring: lacks active monitoring
- Level 1
    - people: data scientists work directly with engineers to convert experiment to repeatable scripts or jobs
    - data gathering: data in databases, pipelines are created for gathering, analysis, and pre-processing
    - development: steps of ML experiment are orchestrated, modularized, and re-usable code is prepared
    - model release: continuous delivery of model
    - no CI/CD but CT pipeline is deployed into production using a semi-manual dpeloyment strategy
    - app integration and testing: unit and integration tests for each model release, less reliant on data scientist's expertise
    - monitoring: active monitoring and retraining triggers are put in place    
- Level 2 (= Level 1 ++)
    - data gathering: strict data governance, secure APIs, role-based data access
    - CI for test, build, package
    - CD pipelines
    - app integration and testing: application code itself contains unit and integration tests for each model release
(a single commit can trigger the whole CI/CD pipeline)

Maturity levels can help:
- estimate scope of work
- establish realistic success criteria
- identify deliverables

MLOps Stack
ML >> dev >> ops
- data garthering and preparation
    - gather, clean, transform batch and streaming data pipelines
- source control
    - version code, data, artifacts, etc.
- experimentation
    - data scientist friendly
    - host notebooks for development
- hyperparameter tuning
    - tuning framework to select the best combination
- distributed model training
    - auto-scaling and distributed model training
    - CI/CD tools for scheduling, task queuing
    - selection of resuable components
- autoML
    - automated model training
- deployment
    - automated deployment using container services (e.g. Docker, Kubernetes)
- model registry
    - register: training data, model type, artifacts, training parameters, hyperparameters, performance metrics
- feature store
    - to facilitate collaboration b/w teams
    - reduce duplication
    - reduce feature engineering cost per model
- monitoring
    - should give real-time performance view of deployed models
    - should have alert mechanisms
- governance
    - governance services to control access, implement policy, and track model activity
    - capability to track end-to-end trail of ML assets
- compliance & audit services
    - authorization and authentication
(+ fall-back support, easy scale out, canary A/B framework, co-locate multiple models, security)

platforms: Pachyderm, Algorithmia, MLflow, Kubeflow, Polyaxon, Valohai, Allegro, Seldom, Terminus DB, Superb AI, Tecton
Pachyderm = "git for your data" but lacks monitoring entirely
Algorithmia = deploy, manage, scale
MLflow = library agnostic but not mature in any area
Kubeflow = includes data gathering but not mature in any area

questions to ask when choosing MLOps platform:
- managed or unmanaged solutions for model serving?
    - managed -- Algorithmia, SageMaker, GoogleML, Paperspace
    - unmanaged -- Kubeflow, Seldon, Tensorflow
- security requirements?
    - critical data -- Algorithmia, Seldon, Tensorflow, Kubeflow
    - non-critical data -- Cloud MLOps solutions
- complexity of models?
    - cloud solutions -- AWS, GCP, Azure
    - on-premises -- Algorithmia
- containerization is a must
    - custom container -- Kubeflow, Seldon
    - cloud-provider -- Algorithmia, SageMaker, GoogleML
- CLI VS GUI
    - CLI -- Seldon, Cortex, Optuna
    - GUI -- Kubeflow, MLflow, Polyaxon
- languages and libraries?
    - no Java support -- Plyaxon, Comet, Optuna
    - no Onnx support -- Kubeflow, Polyaxon
- type of ML objective?
    - traditional ML -- MLflow, Metaflow
    - deep learning -- Valohai, Allegro
- specialized platform or end-to-end solution?
    - focused -- Algorithmia, Pachyderm
    - end-to-end -- Valohai, Allegro
    
